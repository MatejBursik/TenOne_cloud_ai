{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pyarrow\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and short information about the columns\n",
    "df = pd.read_parquet('data/price_paid_records.parquet', engine='pyarrow')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Contains all the data cleaning performed in the individual EDA notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial_cleaning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column names based on the old ones\n",
    "new_columns = [col.lower().replace(' ', '_').replace('/', '_') for col in df.columns]\n",
    "new_columns = ['city' if col=='town_city' else col for col in new_columns]\n",
    "new_columns = ['is_new' if col=='old_new' else col for col in new_columns]\n",
    "df.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessery columns\n",
    "df.drop('transaction_unique_identifier', axis=1, inplace=True)\n",
    "df.drop('record_status_-_monthly_file_only', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data types of columns\n",
    "df['date_of_transfer'] = pd.to_datetime(df['date_of_transfer'])\n",
    "df['is_new'] = df['is_new'].map({'Y': True, 'N': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outliers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'Unknown' duration type\n",
    "df = df[~(df['duration'] == 'U')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unrealistically low prices\n",
    "df = df[df['price'] >= 85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliears based on correlation to Property types\n",
    "df = df[\n",
    "    ((df['price'] <= 10000000) & (df['property_type'] == 'T')) | \n",
    "    ((df['price'] <= 5000000) & (df['property_type'] == 'S')) |\n",
    "    ((df['price'] <= 5000000) & (df['property_type'] == 'D')) |\n",
    "    ((df['price'] <= 10000000) & (df['property_type'] == 'F')) |\n",
    "    ((df['price'] <= 30000000) & (df['property_type'] == 'O'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliears based on correlation to New/Old property\n",
    "df = df[\n",
    "    ((df['price'] <= 7500000) & (df['is_new'] == True)) | \n",
    "    ((df['price'] <= 27000000) & (df['is_new'] == False))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data into files\n",
    "Creating dataset for specialized use cases or experimentation\n",
    "- final_all_data - contains all the cleaned data no-matter the date\n",
    "- after_2008_crisis - \n",
    "- after_2016_policy - \n",
    "- location_*city* - contains cleaned data about a specific location, no-matter the date, for price forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final data file\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_parquet('data/final_all_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_of_transfer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset after 2008 DFC\n",
    "cutoff_date = pd.to_datetime('2009-01-01')\n",
    "df_2008 = df[df['date_of_transfer'] >= cutoff_date]\n",
    "df_2008 = df_2008.reset_index(drop=True)\n",
    "\n",
    "# Save data in parquet format\n",
    "print(df_2008.info())\n",
    "df_2008.to_parquet('data/after_2008_crisis.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset after April 2016 policy\n",
    "cutoff_date = pd.to_datetime('2016-04-01')\n",
    "df_2016 = df[df['date_of_transfer'] >= cutoff_date]\n",
    "df_2016 = df_2016.reset_index(drop=True)\n",
    "\n",
    "# Save data in parquet format\n",
    "print(df_2016.info())\n",
    "df_2016.to_parquet('data/after_2016_policy.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location_data.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
