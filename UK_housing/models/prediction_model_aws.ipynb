{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matej Buršík"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret\n",
      "  Using cached pycaret-3.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (8.28.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (8.1.5)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (4.66.5)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (1.5.3)\n",
      "Requirement already satisfied: jinja2>=3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (3.1.4)\n",
      "Collecting scipy<=1.11.4,>=1.6.1 (from pycaret)\n",
      "  Using cached scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib<1.4,>=1.2.0 (from pycaret)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: scikit-learn>1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (1.5.2)\n",
      "Collecting pyod>=1.1.3 (from pycaret)\n",
      "  Using cached pyod-2.0.2-py3-none-any.whl\n",
      "Collecting imbalanced-learn>=0.12.0 (from pycaret)\n",
      "  Using cached imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting category-encoders>=2.4.0 (from pycaret)\n",
      "  Using cached category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting lightgbm>=3.0.0 (from pycaret)\n",
      "  Using cached lightgbm-4.5.0-py3-none-linux_x86_64.whl\n",
      "Requirement already satisfied: numba>=0.55.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (0.60.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (6.0.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (6.11.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (5.10.4)\n",
      "Requirement already satisfied: cloudpickle in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (2.2.1)\n",
      "Collecting deprecation>=2.1.0 (from pycaret)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from pycaret)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting matplotlib<3.8.0 (from pycaret)\n",
      "  Using cached matplotlib-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-plot>=0.3.7 (from pycaret)\n",
      "  Using cached scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting yellowbrick>=1.4 (from pycaret)\n",
      "  Using cached yellowbrick-1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: plotly>=5.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (5.24.1)\n",
      "Collecting kaleido>=0.2.1 (from pycaret)\n",
      "  Using cached kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting schemdraw==0.15 (from pycaret)\n",
      "  Using cached schemdraw-0.15-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting plotly-resampler>=0.8.3.1 (from pycaret)\n",
      "  Using cached plotly_resampler-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (0.14.4)\n",
      "Collecting sktime==0.26.0 (from pycaret)\n",
      "  Using cached sktime-0.26.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tbats>=1.1.3 (from pycaret)\n",
      "  Using cached tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pmdarima>=2.0.4 (from pycaret)\n",
      "  Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: wurlitzer in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pycaret) (3.1.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sktime==0.26.0->pycaret) (21.3)\n",
      "Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret)\n",
      "  Using cached scikit_base-0.7.8-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting scikit-learn>1.4.0 (from pycaret)\n",
      "  Using cached scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata>=4.12.0->pycaret) (3.20.2)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (2.9.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<2.2.0->pycaret) (2024.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly>=5.14.0->pycaret) (9.0.0)\n",
      "Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (3.0.11)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (75.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (2024.8.30)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.4)\n",
      "Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting retrying (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Using cached retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.3.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from patsy>=0.5.1->category-encoders>=2.4.0->pycaret) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.8.2)\n",
      "Using cached pycaret-3.3.2-py3-none-any.whl (486 kB)\n",
      "Using cached schemdraw-0.15-py3-none-any.whl (106 kB)\n",
      "Using cached sktime-0.26.0-py3-none-any.whl (21.8 MB)\n",
      "Using cached category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "Using cached matplotlib-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n",
      "Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "Using cached scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Using cached scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "Using cached tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "Using cached yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
      "Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Using cached orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached scikit_base-0.7.8-py3-none-any.whl (130 kB)\n",
      "Using cached tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: kaleido, dash-table, dash-html-components, dash-core-components, xxhash, tsdownsample, scipy, scikit-base, schemdraw, retrying, orjson, joblib, scikit-learn, matplotlib, lightgbm, deprecation, yellowbrick, sktime, scikit-plot, pyod, imbalanced-learn, dash, pmdarima, plotly-resampler, category-encoders, tbats, pycaret\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.9.2\n",
      "    Uninstalling matplotlib-3.9.2:\n",
      "      Successfully uninstalled matplotlib-3.9.2\n",
      "Successfully installed category-encoders-2.6.4 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 imbalanced-learn-0.12.4 joblib-1.3.2 kaleido-0.2.1 lightgbm-4.5.0 matplotlib-3.7.5 orjson-3.10.12 plotly-resampler-0.10.0 pmdarima-2.0.4 pycaret-3.3.2 pyod-2.0.2 retrying-1.3.4 schemdraw-0.15 scikit-base-0.7.8 scikit-learn-1.4.2 scikit-plot-0.3.7 scipy-1.11.4 sktime-0.26.0 tbats-1.1.3 tsdownsample-0.1.3 xxhash-3.5.0 yellowbrick-1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "import pandas as pd\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6076289 entries, 0 to 6076288\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   price             int64         \n",
      " 1   date_of_transfer  datetime64[ns]\n",
      " 2   property_type     object        \n",
      " 3   is_new            bool          \n",
      " 4   duration          object        \n",
      " 5   city              object        \n",
      " 6   district          object        \n",
      " 7   county            object        \n",
      " 8   ppdcategory_type  object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(1), object(6)\n",
      "memory usage: 376.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "df = pd.read_parquet('../data/after_2008_crisis.parquet', engine='pyarrow')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17a97_row9_col1, #T_17a97_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17a97\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17a97_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_17a97_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_17a97_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_17a97_row0_col1\" class=\"data row0 col1\" >1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_17a97_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_17a97_row1_col1\" class=\"data row1 col1\" >price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_17a97_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_17a97_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_17a97_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_17a97_row3_col1\" class=\"data row3 col1\" >(6076289, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_17a97_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_17a97_row4_col1\" class=\"data row4 col1\" >(6076289, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_17a97_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_17a97_row5_col1\" class=\"data row5 col1\" >(4253402, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_17a97_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_17a97_row6_col1\" class=\"data row6 col1\" >(1822887, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_17a97_row7_col0\" class=\"data row7 col0\" >Date features</td>\n",
       "      <td id=\"T_17a97_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_17a97_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n",
       "      <td id=\"T_17a97_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_17a97_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_17a97_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_17a97_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_17a97_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_17a97_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_17a97_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_17a97_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_17a97_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_17a97_row13_col0\" class=\"data row13 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_17a97_row13_col1\" class=\"data row13 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_17a97_row14_col0\" class=\"data row14 col0\" >Encoding method</td>\n",
       "      <td id=\"T_17a97_row14_col1\" class=\"data row14 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_17a97_row15_col0\" class=\"data row15 col0\" >Normalize</td>\n",
       "      <td id=\"T_17a97_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_17a97_row16_col0\" class=\"data row16 col0\" >Normalize method</td>\n",
       "      <td id=\"T_17a97_row16_col1\" class=\"data row16 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_17a97_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_17a97_row17_col1\" class=\"data row17 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_17a97_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_17a97_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_17a97_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_17a97_row19_col1\" class=\"data row19 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_17a97_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_17a97_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_17a97_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_17a97_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_17a97_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_17a97_row22_col1\" class=\"data row22 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17a97_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_17a97_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_17a97_row23_col1\" class=\"data row23 col1\" >a926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd3a7cc88b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize setup\n",
    "exp_clf = setup(data=df, target='price', normalize=True, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>sklearn.linear_model._base.LinearRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>sklearn.linear_model._coordinate_descent.Lasso</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>sklearn.linear_model._ridge.Ridge</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>sklearn.linear_model._coordinate_descent.Elast...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lar</th>\n",
       "      <td>Least Angle Regression</td>\n",
       "      <td>sklearn.linear_model._least_angle.Lars</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llar</th>\n",
       "      <td>Lasso Least Angle Regression</td>\n",
       "      <td>sklearn.linear_model._least_angle.LassoLars</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omp</th>\n",
       "      <td>Orthogonal Matching Pursuit</td>\n",
       "      <td>sklearn.linear_model._omp.OrthogonalMatchingPu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>sklearn.linear_model._bayes.BayesianRidge</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ard</th>\n",
       "      <td>Automatic Relevance Determination</td>\n",
       "      <td>sklearn.linear_model._bayes.ARDRegression</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par</th>\n",
       "      <td>Passive Aggressive Regressor</td>\n",
       "      <td>sklearn.linear_model._passive_aggressive.Passi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ransac</th>\n",
       "      <td>Random Sample Consensus</td>\n",
       "      <td>sklearn.linear_model._ransac.RANSACRegressor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>TheilSen Regressor</td>\n",
       "      <td>sklearn.linear_model._theil_sen.TheilSenRegressor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>Huber Regressor</td>\n",
       "      <td>sklearn.linear_model._huber.HuberRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kr</th>\n",
       "      <td>Kernel Ridge</td>\n",
       "      <td>sklearn.kernel_ridge.KernelRidge</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>sklearn.svm._classes.SVR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>sklearn.neighbors._regression.KNeighborsRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Regressor</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostRegr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbr</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Regressor</td>\n",
       "      <td>sklearn.dummy.DummyRegressor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name  \\\n",
       "ID                                            \n",
       "lr                        Linear Regression   \n",
       "lasso                      Lasso Regression   \n",
       "ridge                      Ridge Regression   \n",
       "en                              Elastic Net   \n",
       "lar                  Least Angle Regression   \n",
       "llar           Lasso Least Angle Regression   \n",
       "omp             Orthogonal Matching Pursuit   \n",
       "br                           Bayesian Ridge   \n",
       "ard       Automatic Relevance Determination   \n",
       "par            Passive Aggressive Regressor   \n",
       "ransac              Random Sample Consensus   \n",
       "tr                       TheilSen Regressor   \n",
       "huber                       Huber Regressor   \n",
       "kr                             Kernel Ridge   \n",
       "svm               Support Vector Regression   \n",
       "knn                   K Neighbors Regressor   \n",
       "dt                  Decision Tree Regressor   \n",
       "rf                  Random Forest Regressor   \n",
       "et                    Extra Trees Regressor   \n",
       "ada                      AdaBoost Regressor   \n",
       "gbr             Gradient Boosting Regressor   \n",
       "mlp                           MLP Regressor   \n",
       "lightgbm    Light Gradient Boosting Machine   \n",
       "dummy                       Dummy Regressor   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr              sklearn.linear_model._base.LinearRegression   True  \n",
       "lasso        sklearn.linear_model._coordinate_descent.Lasso   True  \n",
       "ridge                     sklearn.linear_model._ridge.Ridge   True  \n",
       "en        sklearn.linear_model._coordinate_descent.Elast...   True  \n",
       "lar                  sklearn.linear_model._least_angle.Lars   True  \n",
       "llar            sklearn.linear_model._least_angle.LassoLars   True  \n",
       "omp       sklearn.linear_model._omp.OrthogonalMatchingPu...   True  \n",
       "br                sklearn.linear_model._bayes.BayesianRidge   True  \n",
       "ard               sklearn.linear_model._bayes.ARDRegression  False  \n",
       "par       sklearn.linear_model._passive_aggressive.Passi...   True  \n",
       "ransac         sklearn.linear_model._ransac.RANSACRegressor  False  \n",
       "tr        sklearn.linear_model._theil_sen.TheilSenRegressor  False  \n",
       "huber            sklearn.linear_model._huber.HuberRegressor   True  \n",
       "kr                         sklearn.kernel_ridge.KernelRidge  False  \n",
       "svm                                sklearn.svm._classes.SVR  False  \n",
       "knn       sklearn.neighbors._regression.KNeighborsRegressor   True  \n",
       "dt              sklearn.tree._classes.DecisionTreeRegressor   True  \n",
       "rf           sklearn.ensemble._forest.RandomForestRegressor   True  \n",
       "et             sklearn.ensemble._forest.ExtraTreesRegressor   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostRegr...   True  \n",
       "gbr          sklearn.ensemble._gb.GradientBoostingRegressor   True  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "lightgbm                     lightgbm.sklearn.LGBMRegressor   True  \n",
       "dummy                          sklearn.dummy.DummyRegressor   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c1a1b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c1a1b_row0_col0, #T_c1a1b_row1_col0, #T_c1a1b_row1_col1, #T_c1a1b_row1_col2, #T_c1a1b_row1_col3, #T_c1a1b_row1_col4, #T_c1a1b_row1_col5, #T_c1a1b_row1_col6, #T_c1a1b_row2_col0, #T_c1a1b_row2_col1, #T_c1a1b_row2_col2, #T_c1a1b_row2_col3, #T_c1a1b_row2_col4, #T_c1a1b_row2_col5, #T_c1a1b_row2_col6, #T_c1a1b_row3_col0, #T_c1a1b_row3_col1, #T_c1a1b_row3_col2, #T_c1a1b_row3_col3, #T_c1a1b_row3_col4, #T_c1a1b_row3_col5, #T_c1a1b_row3_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c1a1b_row0_col1, #T_c1a1b_row0_col2, #T_c1a1b_row0_col3, #T_c1a1b_row0_col4, #T_c1a1b_row0_col5, #T_c1a1b_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_c1a1b_row0_col7, #T_c1a1b_row1_col7, #T_c1a1b_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_c1a1b_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c1a1b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1a1b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c1a1b_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_c1a1b_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_c1a1b_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_c1a1b_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_c1a1b_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_c1a1b_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_c1a1b_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a1b_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_c1a1b_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_c1a1b_row0_col1\" class=\"data row0 col1\" >45349.3531</td>\n",
       "      <td id=\"T_c1a1b_row0_col2\" class=\"data row0 col2\" >3982647587.2788</td>\n",
       "      <td id=\"T_c1a1b_row0_col3\" class=\"data row0 col3\" >63108.1518</td>\n",
       "      <td id=\"T_c1a1b_row0_col4\" class=\"data row0 col4\" >0.5864</td>\n",
       "      <td id=\"T_c1a1b_row0_col5\" class=\"data row0 col5\" >0.3638</td>\n",
       "      <td id=\"T_c1a1b_row0_col6\" class=\"data row0 col6\" >0.4088</td>\n",
       "      <td id=\"T_c1a1b_row0_col7\" class=\"data row0 col7\" >70.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a1b_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_c1a1b_row1_col0\" class=\"data row1 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_c1a1b_row1_col1\" class=\"data row1 col1\" >49899.0837</td>\n",
       "      <td id=\"T_c1a1b_row1_col2\" class=\"data row1 col2\" >4580854286.6394</td>\n",
       "      <td id=\"T_c1a1b_row1_col3\" class=\"data row1 col3\" >67681.9441</td>\n",
       "      <td id=\"T_c1a1b_row1_col4\" class=\"data row1 col4\" >0.5243</td>\n",
       "      <td id=\"T_c1a1b_row1_col5\" class=\"data row1 col5\" >0.3910</td>\n",
       "      <td id=\"T_c1a1b_row1_col6\" class=\"data row1 col6\" >0.4528</td>\n",
       "      <td id=\"T_c1a1b_row1_col7\" class=\"data row1 col7\" >33.4720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a1b_level0_row2\" class=\"row_heading level0 row2\" >lasso</th>\n",
       "      <td id=\"T_c1a1b_row2_col0\" class=\"data row2 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_c1a1b_row2_col1\" class=\"data row2 col1\" >49898.9566</td>\n",
       "      <td id=\"T_c1a1b_row2_col2\" class=\"data row2 col2\" >4580854583.9235</td>\n",
       "      <td id=\"T_c1a1b_row2_col3\" class=\"data row2 col3\" >67681.9463</td>\n",
       "      <td id=\"T_c1a1b_row2_col4\" class=\"data row2 col4\" >0.5243</td>\n",
       "      <td id=\"T_c1a1b_row2_col5\" class=\"data row2 col5\" >0.3910</td>\n",
       "      <td id=\"T_c1a1b_row2_col6\" class=\"data row2 col6\" >0.4528</td>\n",
       "      <td id=\"T_c1a1b_row2_col7\" class=\"data row2 col7\" >136.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a1b_level0_row3\" class=\"row_heading level0 row3\" >lar</th>\n",
       "      <td id=\"T_c1a1b_row3_col0\" class=\"data row3 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_c1a1b_row3_col1\" class=\"data row3 col1\" >49898.9347</td>\n",
       "      <td id=\"T_c1a1b_row3_col2\" class=\"data row3 col2\" >4580854624.8997</td>\n",
       "      <td id=\"T_c1a1b_row3_col3\" class=\"data row3 col3\" >67681.9466</td>\n",
       "      <td id=\"T_c1a1b_row3_col4\" class=\"data row3 col4\" >0.5243</td>\n",
       "      <td id=\"T_c1a1b_row3_col5\" class=\"data row3 col5\" >0.3910</td>\n",
       "      <td id=\"T_c1a1b_row3_col6\" class=\"data row3 col6\" >0.4528</td>\n",
       "      <td id=\"T_c1a1b_row3_col7\" class=\"data row3 col7\" >32.3420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd2a773f4f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(n_jobs=1, random_state=1559)\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "# options:\n",
    "# budget_time = 300 //in seconds\n",
    "try:\n",
    "    best_model = compare_models(fold=5, include=['lr', 'lasso', 'lar', 'lightgbm'])\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    best_model = None\n",
    "\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>21:05:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                \\\n",
       "                                                 \n",
       "Initiated  . . . . . . . . . . . . . . . . . .   \n",
       "Status     . . . . . . . . . . . . . . . . . .   \n",
       "Estimator  . . . . . . . . . . . . . . . . . .   \n",
       "\n",
       "                                            \n",
       "                                            \n",
       "Initiated                         21:05:22  \n",
       "Status           Searching Hyperparameters  \n",
       "Estimator  Light Gradient Boosting Machine  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc3e5e4e274ca49802e2b0915efb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828061, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193843.583978\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.668169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828061, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193832.468201\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.637653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193835.177960\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193848.088676\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193822.404532\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193841.079736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193842.203088\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193844.984097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193846.349145\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193801.758361\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.734203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828061, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193843.583978\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828061, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193832.468201\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193835.177960\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193848.088676\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193822.404532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 3828062, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 193841.079736\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use Linear Regression if no valid model is found\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     tuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predict_model(tuned_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/utils/generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[0;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/regression/functional.py:1197\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[1;32m   1007\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1026\u001b[0m ):\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_library\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_library\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tuner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tuner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtuner_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuner_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/regression/oop.py:1499\u001b[0m, in \u001b[0;36mRegressionExperiment.tune_model\u001b[0;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1309\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1328\u001b[0m ):\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \n\u001b[1;32m   1497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_library\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_library\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tuner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tuner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtuner_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuner_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:2680\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[0;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[1;32m   2673\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.sample_without_replacement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2674\u001b[0m         pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_sample_without_replacement,\n\u001b[1;32m   2675\u001b[0m     ):\n\u001b[1;32m   2676\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[1;32m   2677\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.ParameterGrid.__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2678\u001b[0m             pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_ParameterGrid_getitem,\n\u001b[1;32m   2679\u001b[0m         ):\n\u001b[0;32m-> 2680\u001b[0m             \u001b[43mmodel_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2682\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/internal/pipeline.py:273\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    272\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 273\u001b[0m     X, y, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/internal/pipeline.py:249\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m         cloned\u001b[38;5;241m.\u001b[39m_cache_full_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Fit or load the current transformer from cache\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_memory_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_transform(\n\u001b[1;32m    257\u001b[0m         transformer\u001b[38;5;241m=\u001b[39mfitted_transformer,\n\u001b[1;32m    258\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    259\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# transformer (necessary when loading from the cache)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/internal/pipeline.py:69\u001b[0m, in \u001b[0;36m_fit_one\u001b[0;34m(transformer, X, y, message, params)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m signature(transformer\u001b[38;5;241m.\u001b[39mfit)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m     68\u001b[0m             args\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m---> 69\u001b[0m         \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformer\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py:229\u001b[0m, in \u001b[0;36mTransformerWrapper.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m transformer_params \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/category_encoders/utils.py:320\u001b[0m, in \u001b[0;36mBaseEncoder.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns to be encoded can not contain null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# for finding invariant columns transform without y (as is done on the test set)\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_out_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Issue#437\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/category_encoders/target_encoder.py:182\u001b[0m, in \u001b[0;36mTargetEncoder._fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     X_hier_ordinal \u001b[38;5;241m=\u001b[39m enc_hier\u001b[38;5;241m.\u001b[39mtransform(X_hier)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder \u001b[38;5;241m=\u001b[39m OrdinalEncoder(\n\u001b[1;32m    177\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    178\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[1;32m    179\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    180\u001b[0m     handle_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m )\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m X_ordinal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordinal_encoder\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhierarchy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/category_encoders/utils.py:320\u001b[0m, in \u001b[0;36mBaseEncoder.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns to be encoded can not contain null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# for finding invariant columns transform without y (as is done on the test set)\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_out_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Issue#437\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/category_encoders/ordinal.py:102\u001b[0m, in \u001b[0;36mOrdinalEncoder._fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping_supplied:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m _, categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal_encoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_missing\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m categories\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/category_encoders/ordinal.py:226\u001b[0m, in \u001b[0;36mOrdinalEncoder.ordinal_encoding\u001b[0;34m(X_in, mapping, cols, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m    225\u001b[0m     nan_identity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m--> 226\u001b[0m     categories \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# make nan last category\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(categories)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/series.py:2242\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2186\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/base.py:1001\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/algorithms.py:409\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/algorithms.py:425\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m table \u001b[38;5;241m=\u001b[39m htable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 425\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use Linear Regression if no valid model is found\n",
    "if best_model is not None:\n",
    "    tuned_model = tune_model(best_model)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = predict_model(tuned_model)\n",
    "    evaluate_model(tuned_model)\n",
    "\n",
    "    # Save the model\n",
    "    save_model(tuned_model, 'model')\n",
    "else:\n",
    "    print(\"No valid model found, using Linear Regression instead.\")\n",
    "    # Initialize regression setup\n",
    "    exp_reg = setup(data=df, target='target', verbose=True, normalize=True)\n",
    "    \n",
    "    # Create and tune Linear Regression model\n",
    "    lr_model = create_model('lr')\n",
    "    tuned_lr_model = tune_model(lr_model)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = predict_model(tuned_lr_model)\n",
    "    evaluate_model(tuned_lr_model)\n",
    "\n",
    "    # Save the Linear Regression model\n",
    "    save_model(tuned_lr_model, 'linear_regression_model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
